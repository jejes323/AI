# -*- coding: utf-8 -*-
"""November06_22-2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1v4UF9rTZrm2Wx9CJdQPeZeScBCfAf3Yy
"""

!pip install spacy
!pip install ginza ja-ginza

from google.colab import drive
drive.mount('/content/drive')

import spacy
import ginza

nlp = spacy.load('ja_ginza')

f1 = open('/content/drive/MyDrive/ColabNotebooks/konanutf8.txt','r', encoding='UTF-8')
f2 = open('/content/drive/MyDrive/ColabNotebooks/kadai2-1.txt', 'w', encoding='UTF-8')
f3 = open('/content/drive/MyDrive/ColabNotebooks/kadai2-2.txt', 'w', encoding='UTF-8')

test1 = f1.read()

# 학번이름
f2.write("学籍番号:72570001\n")
f2.write("名前:SEO YEONGWOO\n")

# 고난대학 횟수
count_konan = test1.count('甲南大学')
f2.write(f"甲南大学の出現回数は {count_konan}\n")

# 형태소 분석

noun_count = 0 # 명사 카운트
aux_count = 0 # 형용사 카운트
places = {}

m = nlp(test1)
for sent in m.sents:
  for token in sent:
    # 명사
    if token.pos_ == "NOUN" and "名詞-普通名詞" in token.tag_:
      f2.write(f"{token.i} {token.orth_} {token.lemma_} {token.pos_} {token.tag_}\n")
      noun_count += 1
for sent in m.sents:
  for token in sent:
    # 형용사
    if token.pos_ == "AUX" and "形容詞" in token.tag_:
      f2.write(f"{token.i} {token.orth_} {token.lemma_} {token.pos_} {token.tag_}\n")
      aux_count += 1

f2.write(f"普通名詞の出現回数は {noun_count}\n")
f2.write(f"形容詞の出現回数は {aux_count}\n")

# 지명 출력 횟수
for sent in m.sents:
  for token in sent:
    if "名詞-固有名詞-地名" in token.tag_:
      name = token.orth_
      if name in places:
        places[name] += 1
      else:
        places[name] = 1

sorted_places = sorted(places.items(), key=lambda x: x[1], reverse=True)
for name, count in sorted_places:
    f3.write(f"{name}：{count} 回\n")


f1.close()
f2.close()
f3.close()